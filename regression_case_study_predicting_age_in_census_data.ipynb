{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58fda33d",
   "metadata": {},
   "source": [
    "## Statistical Modeling and Performance Evaluation<a href=\"#Statistical-Modeling-and-Performance-Evaluation\" class=\"anchor-link\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d49ec8a",
   "metadata": {},
   "source": [
    "### Full Model<a href=\"#Full-Model\" class=\"anchor-link\"></a>\n",
    "\n",
    "We begin by fitting a multiple linear regression that predicts `age`\n",
    "using all of the available features. We call this the full model. First\n",
    "let's take a quick peak at the clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d58707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a3ebc",
   "metadata": {},
   "source": [
    "When constructing the regression formula, we can manually add all the\n",
    "independent features. On the other hand, if there are lots of\n",
    "independent variables, we can get smart and use some string function\n",
    "tricks as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c00a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short and sweet\n",
    "formula_string_indep_vars = ' + '.join(data.drop(columns='age').columns)\n",
    "formula_string = 'age ~ ' + formula_string_indep_vars\n",
    "print('formula_string: ', formula_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a27046",
   "metadata": {},
   "source": [
    "The formula string above works just fine with the `Statsmodels` module.\n",
    "The problem, however, is that we cannot do automatic variable selection\n",
    "with this formula. What we need for this purpose is \"one-hot-encoding\"\n",
    "of categorical features. For more information on this encoding, please\n",
    "refer to [this\n",
    "page](https://www.featureranking.com/tutorials/machine-learning-tutorials/data-preparation-for-machine-learning/).\n",
    "\n",
    "In the code chunk below, we first use the `get_dummies()` function in\n",
    "`Pandas` for one-hot-encoding of categorical features and then we\n",
    "construct a new formula string with the encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fc3010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoding of categorical features\n",
    "# for this to work correctly, variable data types (numeric or categorical)\n",
    "# must be correctly specified within the Pandas dataframe\n",
    "data_encoded = pd.get_dummies(data, drop_first=True)\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6722f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_string_indep_vars_encoded = ' + '.join(data_encoded.drop(columns='age').columns)\n",
    "formula_string_encoded = 'age ~ ' + formula_string_indep_vars_encoded\n",
    "print('formula_string_encoded: ', formula_string_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e5dd96",
   "metadata": {},
   "source": [
    "For fun, let's add two interaction terms to our full model. Let's add\n",
    "the interaction of the `capital` feature with `hours_per_week` and\n",
    "`race_White` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_string_encoded = formula_string_encoded + ' + hours_per_week:capital + race_White:capital'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefce81b",
   "metadata": {},
   "source": [
    "Also, let's add the square of the `hours_per_week` feature to illustrate\n",
    "how we can add higher order terms to our linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8129d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_string_encoded = formula_string_encoded + ' + np.power(hours_per_week, 2)'\n",
    "print('formula_string_encoded: ', formula_string_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9992be",
   "metadata": {},
   "source": [
    "Now that we have defined our statistical model formula as a Python\n",
    "string, we fit an OLS (ordinary least squares) model to our encoded\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccb096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_full = sm.formula.ols(formula=formula_string_encoded, data=data_encoded)\n",
    "###\n",
    "model_full_fitted = model_full.fit()\n",
    "###\n",
    "print(model_full_fitted.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f79fd",
   "metadata": {},
   "source": [
    "The full model has an adjusted R-squared value of 0.405, which means\n",
    "that only 40% of the variance is explained by the model. By looking at\n",
    "the p-values, we observe that the majority of them are highly\n",
    "significant, though there are a few insignificant variables at a 5%\n",
    "level.\n",
    "\n",
    "Let's define a new data frame for actual age vs. predicted age and the\n",
    "residuals for the full model. We will use this data frame when plotting\n",
    "predicted values and the regression residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76667ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_full = pd.DataFrame({'actual': data_encoded['age'], \n",
    "                               'predicted': model_full_fitted.fittedvalues, \n",
    "                               'residual': model_full_fitted.resid})\n",
    "residuals_full.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a166abd8",
   "metadata": {},
   "source": [
    "Let's plot actual age values vs. predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cdd788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(axis, slope, intercept, **kargs):\n",
    "    xmin, xmax = axis.get_xlim()\n",
    "    plt.plot([xmin, xmax], [xmin*slope+intercept, xmax*slope+intercept], **kargs)\n",
    "\n",
    "# Creating scatter plot\n",
    "plt.scatter(residuals_full['actual'], residuals_full['predicted'], alpha=0.3);\n",
    "plot_line(axis=plt.gca(), slope=1, intercept=0, c=\"red\");\n",
    "plt.xlabel('Actual Age');\n",
    "plt.ylabel('Predicted Age');\n",
    "plt.title('Figure 9: Scatter plot of actual vs. predicted age for the Full Model', fontsize=15);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe1e1e6",
   "metadata": {},
   "source": [
    "From Figure 9, we observe that the model never produces a prediction\n",
    "above 80 even though the oldest person in the dataset is 90.\n",
    "\n",
    "We will now check the diagnostics for the full model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23085ee7",
   "metadata": {},
   "source": [
    "### Full Model Diagnostic Checks<a href=\"#Full-Model-Diagnostic-Checks\" class=\"anchor-link\"></a>\n",
    "\n",
    "We would like to check whether there are indications of violations of\n",
    "the regression assumptions, which are\n",
    "\n",
    "1.  linearity of the relationship between target variable and the\n",
    "    independent variables\n",
    "2.  constant variance of the errors\n",
    "3.  normality of the residual distribution\n",
    "4.  statistical independence of the residuals\n",
    "\n",
    "Let's first get a scatter plot of residuals (as a function of predicted\n",
    "`age`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ded72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(residuals_full['predicted'], residuals_full['residual'], alpha=0.3);\n",
    "plt.xlabel('Predicted Age');\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Figure 10(a): Scatterplot of residuals vs. predicted age for Full Model', fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b7db24",
   "metadata": {},
   "source": [
    "From Figure 10(a), we see that, rather than being mostly random and\n",
    "centered around 0, the residuals exhibit a banding pattern, especially\n",
    "when predicted age is below 50. This pattern indicates that the constant\n",
    "variability assumption of linear regression is not quite satisfied in\n",
    "this case.\n",
    "\n",
    "Let's now plot actual age vs. residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51360d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(residuals_full['actual'], residuals_full['residual'], alpha=0.3);\n",
    "plt.xlabel('Actual Age');\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Figure 10(b): Scatterplot of residuals vs. actual age for Full Model', fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ffe35f",
   "metadata": {},
   "source": [
    "We notice that the model overestimates younger ages and underestimates\n",
    "older ages. In particular, for those younger than the age of 30, the\n",
    "model predicts much older ages. Also, for those above the age of 80, the\n",
    "model predicts significantly younger ages.\n",
    "\n",
    "Let's overlay the histograms of actual vs. predicted age on the same\n",
    "plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65609b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(residuals_full['actual'], label='actual', bins=20, alpha=0.7);\n",
    "plt.hist(residuals_full['predicted'], label='predicted', bins=20, alpha=0.7);\n",
    "plt.xlabel('Age');\n",
    "plt.ylabel('Frequency');\n",
    "plt.title('Figure 11: Histograms of actual age vs. predicted age for Full Model', fontsize=15);\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550c22d2",
   "metadata": {},
   "source": [
    "We notice that their distributions are quite different. In particular,\n",
    "the model's predictions are highly clustered around mid-40's.\n",
    "\n",
    "Let's now have look at the histogram of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(residuals_full['residual'], bins = 20);\n",
    "plt.xlabel('Residual');\n",
    "plt.ylabel('Frequency');\n",
    "plt.title('Figure 12: Histogram of residuals for Full Model', fontsize=15);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91c451a",
   "metadata": {},
   "source": [
    "From Figure 12, the histogram of residuals looks somewhat symmetric,\n",
    "though slightly right-skewed. Nonetheless, it seems the normality\n",
    "assumption of linear regression is not significantly violated in this\n",
    "particular case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42eb3a9",
   "metadata": {},
   "source": [
    "### Backwards Feature Selection<a href=\"#Backwards-Feature-Selection\" class=\"anchor-link\"></a>\n",
    "\n",
    "We now perform backwards feature selection using p-values. It appears\n",
    "`Statsmodels` does not have any canned code for automatic feature\n",
    "selection, so we wrote one ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8870c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the patsy model description from formula\n",
    "patsy_description = patsy.ModelDesc.from_formula(formula_string_encoded)\n",
    "\n",
    "# initialize feature-selected fit to full model\n",
    "linreg_fit = model_full_fitted\n",
    "\n",
    "# do backwards elimination using p-values\n",
    "p_val_cutoff = 0.05\n",
    "\n",
    "## WARNING 1: The code below assumes that the Intercept term is present in the model.\n",
    "## WARNING 2: It will work only with main effects and two-way interactions, if any.\n",
    "\n",
    "print('\\nPerforming backwards feature selection using p-values:')\n",
    "\n",
    "while True:\n",
    "\n",
    "    # uncomment the line below if you would like to see the regression summary\n",
    "    # in each step:\n",
    "    ### print(linreg_fit.summary())\n",
    "\n",
    "    pval_series = linreg_fit.pvalues.drop(labels='Intercept')\n",
    "    pval_series = pval_series.sort_values(ascending=False)\n",
    "    term = pval_series.index[0]\n",
    "    pval = pval_series[0]\n",
    "    if (pval < p_val_cutoff):\n",
    "        break\n",
    "    term_components = term.split(':')\n",
    "    print(f'\\nRemoving term \"{term}\" with p-value {pval:.4}')\n",
    "    if (len(term_components) == 1): ## this is a main effect term\n",
    "        patsy_description.rhs_termlist.remove(patsy.Term([patsy.EvalFactor(term_components[0])]))    \n",
    "    else: ## this is an interaction term\n",
    "        patsy_description.rhs_termlist.remove(patsy.Term([patsy.EvalFactor(term_components[0]), \n",
    "                                                        patsy.EvalFactor(term_components[1])]))    \n",
    "\n",
    "    linreg_fit = smf.ols(formula=patsy_description, data=data_encoded).fit()\n",
    "\n",
    "###\n",
    "## this is the clean fit after backwards elimination\n",
    "model_reduced_fitted = smf.ols(formula = patsy_description, data = data_encoded).fit()\n",
    "###\n",
    "\n",
    "#########\n",
    "print(\"\\n***\")\n",
    "print(model_reduced_fitted.summary())\n",
    "print(\"***\")\n",
    "print(f\"Regression number of terms: {len(model_reduced_fitted.model.exog_names)}\")\n",
    "print(f\"Regression F-distribution p-value: {model_reduced_fitted.f_pvalue:.4f}\")\n",
    "print(f\"Regression R-squared: {model_reduced_fitted.rsquared:.4f}\")\n",
    "print(f\"Regression Adjusted R-squared: {model_reduced_fitted.rsquared_adj:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38649ae",
   "metadata": {},
   "source": [
    "Similar to what we did for the full model, let's define a new data frame\n",
    "for actual age vs. predicted age and the residuals for the reduced\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46159121",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_reduced = pd.DataFrame({'actual': data_encoded['age'], \n",
    "                                  'predicted': model_reduced_fitted.fittedvalues, \n",
    "                                  'residual': model_reduced_fitted.resid})\n",
    "residuals_reduced.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ebf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a scatter plot\n",
    "plt.scatter(residuals_reduced['actual'], residuals_reduced['predicted'], alpha=0.3);\n",
    "plot_line(axis=plt.gca(), slope=1, intercept=0, c=\"red\");\n",
    "plt.xlabel('Age');\n",
    "plt.ylabel('Predicted Age');\n",
    "plt.title('Figure 13: Scatter plot of actual vs. predicted age for Reduced Model', fontsize=15);\n",
    "plt.show(); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d2518",
   "metadata": {},
   "source": [
    "This model returns an Adjusted R-squared of 0.404, meaning the reduced\n",
    "model still explains about 40% of the variance, but with 6 less\n",
    "variables. Looking at the p-values, they are all significant at the 5%\n",
    "level, as expected. From Figure 13, we still have the same issues with\n",
    "our model. That is, the model overestimates younger ages and\n",
    "underestimates older ages. We will now perform the diagnostic checks on\n",
    "this reduced model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c144153a",
   "metadata": {},
   "source": [
    "### Reduced Model Diagnostic Checks<a href=\"#Reduced-Model-Diagnostic-Checks\" class=\"anchor-link\"></a>\n",
    "\n",
    "Let's first get a scatter plot of residuals (as a function of predicted\n",
    "age)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9e3656",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(residuals_reduced['predicted'], residuals_reduced['residual'], alpha=0.3);\n",
    "plt.xlabel('Predicted Age');\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Figure 14: Scatter plot of residuals vs. predicted age for Reduced Model', fontsize=15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a63dff",
   "metadata": {},
   "source": [
    "Figure 14 looks very similar to Figure 10(a), suggesting that the\n",
    "residuals exhibit the same banding pattern.\n",
    "\n",
    "Let's now have look at the histogram of the residuals for the reduced\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ca40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(residuals_reduced['residual'], bins = 20);\n",
    "plt.xlabel('Residual');\n",
    "plt.ylabel('Frequency');\n",
    "plt.title('Figure 15: Histogram of residuals for Reduced Model', fontsize = 15)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627bacbf",
   "metadata": {},
   "source": [
    "From Figure 15, there is again a somewhat symmetric histogram around\n",
    "zero, which suggests that the residuals are somewhat normally\n",
    "distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abfda67",
   "metadata": {},
   "source": [
    "## Summary and Conclusions<a href=\"#Summary-and-Conclusions\" class=\"anchor-link\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcaba5d",
   "metadata": {},
   "source": [
    "Using our independent variables, we were able to get a full model with\n",
    "an Adjusted R-squared value of about 40%. After backwards variable\n",
    "selection with a p-value cutoff value of 0.05, we were able to maintain\n",
    "the same performance but with 6 less variables. Our final model has 49\n",
    "variables all together with a model p-value of 0.\n",
    "\n",
    "Diagnostic checks with residual scatter plots indicate that, rather than\n",
    "being random and centered around 0, the residuals exhibit a banding\n",
    "pattern, especially when predicted age is below 50. This pattern\n",
    "indicates that the constant variability assumption of linear regression\n",
    "is not quite satisfied in this case. On the other hand, residual\n",
    "histograms suggest that there are no significant violations of the\n",
    "normality assumption on the residuals.\n",
    "\n",
    "The final multiple linear regression model has an Adjusted R-squared\n",
    "value of about 40%, which is pretty low. So, it appears that the\n",
    "variables we used are not quite adequate for accurately predicting the\n",
    "age of an individual in the 1994 US Census dataset within a multiple\n",
    "linear regression framework. A good next step might involve adding some\n",
    "more interaction terms and maybe some other higher order terms to see if\n",
    "this would result in some improvement for the Adjusted R-squared value.\n",
    "Nonetheless, it might be the case that nonlinear models such as a neural\n",
    "network might be more appropriate for the task at hand rather than a\n",
    "linear regression model.\n",
    "\n",
    "Our regression model appears to predict age correctly within \\$\\\\pm40\\$\n",
    "years in general, though this is clearly a huge margin of error for the\n",
    "model to be useful for any practical purposes. Furthermore, our model\n",
    "has some rather significant issues. Specifically, our model consistently\n",
    "overestimates younger ages and underestimates older ages. In particular,\n",
    "for those younger than the age of 30, the model predicts much older\n",
    "ages. Also, for those above the age of 80, the model predicts\n",
    "significantly younger ages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea9d644",
   "metadata": {},
   "source": [
    "***\n",
    "featureranking.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31faf55945258a74b524bd16d50b6961a7d3d127b3ac12b0b17860d642b0a6e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
